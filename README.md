# DATA PRE-PROCESSING in Python

This repo is part of me learning the basics of data preprocessing in Python.
I made three simple scripts to practice **Ordinal Encoding**, **One-Hot Encoding**, and **Imputation** — all done manually using **Python, Pandas, and NumPy**.

The idea was to understand *how these things actually work* instead of just calling built-in functions like `get_dummies()` or scikit-learn encoders.


## What I Practiced

* Converting text categories to numbers manually
* Creating one-hot encoded columns with loops
* Filling missing values using mean (numeric) and mode (categorical)
* Working with Pandas DataFrames and NumPy arrays for small datasets

Basically, I wanted to get a hands-on feel for preprocessing before diving into real ML models.

## Files

| File                  | What it does                                                                              |
| --------------------- | ----------------------------------------------------------------------------------------- |
| `ordinal_encoding.py` | Turns ordered categories (like Small, Medium, Large) into numbers using a manual mapping. |
| `onehot_encoding.py`  | Makes binary columns for each category using loops and simple NumPy logic.                |
| `imputation.py`       | Fills missing values using mean or mode, all done manually without high-level functions.  |



## What I Learned

* The difference between **ordinal** and **one-hot encoding**
* How to handle missing data manually
* Why preprocessing is important before applying ML models
* Improved comfort with Pandas and NumPy basics


This repo is just a simple record of what I tried and learned — nothing fancy.
If you want, I can also **add a small “example input/output section”** right in the README — it makes your repo feel more complete and professional without making it look AI-generated.

Do you want me to do that?

